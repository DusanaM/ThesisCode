{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from networks import ActorNetwork, ValueNetwork, CriticNetwork\n",
    "from memory_buffer import ReplyBuffer\n",
    "from sac_agent import SAC_Agent\n",
    "\n",
    "class InventoryAITraderSAC:\n",
    "    def __init__(self, sigma, bid_k, bid_a, ask_k, ask_a, dt, memory_size=1000000):\n",
    "        self.sigma = sigma\n",
    "        self.bid_k = bid_k\n",
    "        self.bid_a = bid_a\n",
    "        self.ask_k = ask_k\n",
    "        self.ask_a = ask_a\n",
    "        self.dt = dt\n",
    "\n",
    "        # Create SAC agent\n",
    "        self.agent = SAC_Agent(input_dims=[2], max_action=1, alpha=0.003, beta=0.003, gamma=0.99, n_actions=1,\n",
    "                               memory_size=memory_size, tau=0.005, layer1=256, layer2=256, batch_size=256, reward_scale=2)\n",
    "\n",
    "        # Set initial values for SAC agent\n",
    "        self.agent.scale = 1.0  # Adjust reward scaling if needed\n",
    "\n",
    "    def get_quotes(self, x, q, s, rt, train_mode=False):\n",
    "        cur_state = self.scale_state(q, rt)\n",
    "\n",
    "        if train_mode:\n",
    "            action = self.agent.pick_action([q, rt])\n",
    "            self.agent.remember(cur_state, action, 0, cur_state, False)\n",
    "            self.agent.learn()\n",
    "\n",
    "        action, _ = self.agent.actor.normal_sample(torch.FloatTensor([q, rt]))\n",
    "        gamma = self.scale_gamma(action.numpy())\n",
    "\n",
    "        # Pre-computed values\n",
    "        two_div_gamma = 2 / gamma\n",
    "        g_ss_rt = gamma * self.sigma**2 * rt\n",
    "\n",
    "        # Calculate reservation price and spreads\n",
    "        reservation_price = s - q * g_ss_rt\n",
    "        spread_bid = (g_ss_rt + two_div_gamma * np.log(1 + gamma / self.bid_k)) / 2\n",
    "        spread_ask = (g_ss_rt + two_div_gamma * np.log(1 + gamma / self.ask_k)) / 2\n",
    "\n",
    "        return reservation_price - spread_bid, reservation_price + spread_ask  # Return bid quote, ask quote\n",
    "\n",
    "    def scale_state(self, q, rt):\n",
    "        \"\"\"\n",
    "        Scales state, assumes max inventory is 100\n",
    "        \"\"\"\n",
    "        return [abs(q) / 100, rt]\n",
    "\n",
    "    def scale_gamma(self, action):\n",
    "        \"\"\"\n",
    "        Scales action to gamma\n",
    "        \"\"\"\n",
    "        return max(1e-5, ((action + 1) / 2))\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# trader = InventoryAITraderSAC(sigma=..., bid_k=..., bid_a=..., ask_k=..., ask_a=..., dt=...)\n",
    "# bid, ask = trader.get_quotes(x=..., q=..., s=..., rt=..., train_mode=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
